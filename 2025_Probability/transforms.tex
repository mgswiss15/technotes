\section{Transformations and push-forward}
\begin{frame}{Transformations of random variables}

\structure{Setup:} 
\begin{itemize}
\item $X$ - random variable with values in $T$ (e.g., $\mR^d$)
\item $P_X$ - distribution of $X$ on $T$
\item $g: T \to U$ - measurable function (transformation)
\item $Y = g(X)$ - transformed random variable with values in $U$
\end{itemize}

\vskip 1em
\structure{Question:} If we know $P_X$, what is the distribution $P_Y$ of $Y = g(X)$?

\vskip 1em
\structure{Examples in ML:}
\begin{itemize}
\item $X \sim \mathcal{N}(0, I)$ (simple), $g$ is neural network, $Y = g(X)$ (complex model distribution)
\item data transformation: $X$ is data, $g$ encodes to latent space
\end{itemize}

\end{frame}

\note[enumerate]
{
\item This is the fundamental question in generative modeling
\item We transform a simple distribution to get a complex one
\item The transformation $g$ is typically a neural network
\item We work directly with distributions on value spaces (as established in Section 2)
\item No need to refer back to abstract probability space $(S, \salg, \mP)$
}


\begin{frame}{Push-forward measure}

\structure{Answer:} distribution of $Y = g(X)$ is the push-forward of $P_X$ by $g$

\vskip 0.5em
\structure{Definition:} $P_Y$ on $U$ defined by
\[
P_Y(C) = P_X(g^{-1}(C)) \quad \text{for } C \subseteq U
\]
where $g^{-1}(C) = \{x \in T: g(x) \in C\}$ is the pre-image

\vskip 1em
\centering
\scalebox{0.55}{
\begin{tikzpicture}[>=Stealth]
% LEFT: domain T with mesh and rectangular g^{-1}(C)
\begin{scope}[shift={(-5,0)}]
    \node at (0,2) {$T$};
    % Mesh (vertical)
    \foreach \x in {-1.5,-1,...,1}
        \draw[gray!70] (\x,-2) -- (\x,2);
    % Mesh (horizontal)
    \foreach \y in {-1.5,-1,...,1.5}
        \draw[gray!70] (-2,\y) -- (1.5,\y);
    % Preimage region g^{-1}(C): ALIGNED WITH GRID
    \fill[blue!25,opacity=0.5] (-1,-1) rectangle (0.5,1);
    \draw[blue!60,thick] (-1,-1) rectangle (0.5,1);
    \node[blue!80] at (-0.2,0) {$g^{-1}(C)$};
\end{scope}
% Middle arrow: g
\draw[->,thick] (-2.5,0.5) -- (-0.5,0.5) node[midway,above] {$g: T \to U$};
\draw[<-,thick] (-2.5,-0.5) -- (-0.5,-0.5) node[midway,above] {preimage};
\node at (-1.5,1.8) {\color{carnelian}$P_X(g^{-1}(C)) = P_Y(C)$};
% RIGHT: codomain U with warped mesh + image C
\begin{scope}[shift={(2,0)}]
    \node at (0,2) {$U$};
    % Warped vertical mesh lines
    \foreach \x in {-1.5,-1,...,1}
    \draw[gray!70,domain=-2:2,smooth,variable=\t]
        plot ({0.9*\x + 0.5*sin(\t r)}, {\t + 0.5*sin(\x r)});
    % Warped horizontal mesh lines
    \foreach \y in {-1.5,-1,...,1.5}
    \draw[gray!70,domain=-2:1.5,smooth,variable=\t]
        plot ({0.9*\t + 0.5*sin(\y r)}, {\y + 0.5*sin(\t r)});
    % Image region C
    \begin{scope}
        \fill[blue!25,opacity=0.5]
            plot[domain=-1:0.5,smooth,variable=\x]
                ({0.9*\x + 0.5*sin(-1 r)}, {-1 + 0.5*sin(\x r)})
            -- plot[domain=-1:1,smooth,variable=\y]
                ({0.9*0.5 + 0.5*sin(\y r)}, {\y + 0.5*sin(0.5 r)})
            -- plot[domain=0.5:-1,smooth,variable=\x]
                ({0.9*\x + 0.5*sin(1 r)}, {1 + 0.5*sin(\x r)})
            -- plot[domain=1:-1,smooth,variable=\y]
                ({0.9*(-1) + 0.5*sin(\y r)}, {\y + 0.5*sin(-1 r)})
            -- cycle;
        \draw[blue!60,thick]
            plot[domain=-1:0.5,smooth,variable=\x]
                ({0.9*\x + 0.5*sin(-1 r)}, {-1 + 0.5*sin(\x r)})
            -- plot[domain=-1:1,smooth,variable=\y]
                ({0.9*0.5 + 0.5*sin(\y r)}, {\y + 0.5*sin(0.5 r)})
            -- plot[domain=0.5:-1,smooth,variable=\x]
                ({0.9*\x + 0.5*sin(1 r)}, {1 + 0.5*sin(\x r)})
            -- plot[domain=1:-1,smooth,variable=\y]
                ({0.9*(-1) + 0.5*sin(\y r)}, {\y + 0.5*sin(-1 r)})
            -- cycle;
        \node[blue!80] at (-0.2,-0.1) {$C$};
    \end{scope}
\end{scope}
\end{tikzpicture}
}

\vskip 0.5em
\structure{Intuition:} probability of $Y$ landing in $C$ equals probability of $X$ being in pre-image

\end{frame}

\note[enumerate]
{
\item Push-forward is how distributions transform under functions
\item The pre-image $g^{-1}(C)$ is the set of points in $T$ that map to $C$
\item Diagram shows: regular grid in $T$ becomes warped in $U$, but probability is preserved
\item This is well-defined because $g$ is measurable
\item In ML: $g$ is neural network, $P_X$ is simple distribution (e.g., Gaussian), $P_Y$ is complex model distribution
\item We're working directly with distributions $P_X$ and $P_Y$, not going back to abstract probability space
}

\begin{frame}{Example: uniform distribution and affine transformation}

\structure{Setup:} $X \sim \text{Uniform}[0, 1]$, transformation $g(x) = 2x + 3$, find distribution of $Y = g(X)$

\vskip 0.5em
\begin{center}  
\scalebox{0.75}{
\begin{tikzpicture}[>=Stealth]
% LEFT: X ~ Uniform[0,1]
\begin{scope}[shift={(-4,0)}]
    \node at (2.3,2.8) {$X \sim \text{Uniform}[0,1]$};
    
    % Axis
    \draw[->] (-0.5,0) -- (4,0) node[right] {$x$};
    \draw[->] (0,-0.3) -- (0,2.5) node[above] {$p_X(x)$};
    
    % Uniform density
    \fill[blue!20,opacity=0.6] (0,0) rectangle (3,2);
    \draw[blue,thick] (0,0) -- (0,2) -- (3,2) -- (3,0);
    
    % Highlighted interval [0.25, 0.75] (50% probability)
    \fill[blue!50,opacity=0.8] (0.75,0) rectangle (2.25,2);
    
    % Labels
    \node[below] at (0,0) {$0$};
    \node[below] at (3,0) {$1$};
    \node[left] at (0,2) {$1$};
    \node[below] at (0.75,0) {\small $0.25$};
    \node[below] at (2.25,0) {\small $0.75$};
   
    % Probability in middle
    \node at (1.5,1) {$P_X(g^{-1}(C)) = 0.5$};
    
    % Probability annotation
    \draw[<->,thick] (0.75,-0.8) -- (2.25,-0.8);
    \node[below] at (1.5,-0.8) {\small length $= 0.5$};
    \node[above] at (1.5,-0.8) {\small $g^{-1}(C) = [-1, 1]$};
\end{scope}

% Arrow with transformation
\node at (1.5,-0.8) {\color{carnelian}$P_X(g^{-1}(C)) = P_Y(C) = 0.5$};
\draw[->,very thick] (-0,1.5) -- (2.5,1.5) node[midway,above] {$g(x) = 2x+3$};
\draw[<-,thick] (-0,0.5) -- (2.5,0.5) node[midway,above] {preimage};

% RIGHT: Y ~ Uniform[3,5]
\begin{scope}[shift={(0.5,0)}]
    \node at (5.7,2.8) {$Y \sim \text{Uniform}[3,5]$};
    
    % Axis
    \draw[->] (2.5,0) -- (9.5,0) node[right] {$y$};
    \draw[->] (3,-0.3) -- (3,2.5) node[above] {$p_Y(y)$};
    
    % Uniform density on [3,5]
    \fill[red!20,opacity=0.6] (3,0) rectangle (9,1);
    \draw[red,thick] (3,0) -- (3,1) -- (9,1) -- (9,0);
    
    % Highlighted interval [3.5, 4.5] = g([0.25, 0.75])
    \fill[red!50,opacity=0.8] (4.5,0) rectangle (7.5,1);
    
    % Labels
    \node[below] at (3,0) {$3$};
    \node[below] at (9,0) {$5$};
    \node[left] at (3,1) {$\frac{1}{2}$};
    \node[below] at (4.5,0) {\small $3.5$};
    \node[below] at (7.5,0) {\small $4.5$};
      
    % Probability in middle
    \node at (6,0.5) {$P_Y(C) = 0.5$};
    
    % Probability annotation
    \draw[<->,thick] (4.5,-0.8) -- (7.5,-0.8);
    \node[below] at (6,-0.8) {\small length $= 1$};
    \node[above] at (6,-0.8) {\small $C = [3.5, 4.5]$};
\end{scope}
\end{tikzpicture}
}
\end{center}

\structure{Key insight:}
\begin{itemize}
\item $g$ stretches space: interval length doubles ($0.5 \to 1$)
\item same probability distributed over larger space
\item density halves: $p_Y = \frac{1}{2} p_X$
\end{itemize}

\alert{Stretching space $\Rightarrow$ lower density (probability conserved)}

\end{frame}

\note[enumerate]
{
\item This is a simple concrete example showing push-forward
\item The preimage calculation: solve $a \leq 2x+3 \leq b$ for $x$
\item Uniform on $[0,1]$: $P_X([a,b]) = b - a$ when $[a,b] \subseteq [0,1]$
\item After transformation: still uniform, but on $[3,5]$ instead of $[0,1]$
\item The scaling factor 2 will become important when we look at densities (Jacobian)
\item This example shows: push-forward preserves the "shape" but changes location and scale
}

\begin{frame}{Example: Gaussian distribution and affine transformation}

\structure{Setup:} $X \sim \mathcal{N}(0, 1)$, transformation $g(x) = 2x + 3$, find distribution of $Y = g(X)$

\vskip 0.5em
\begin{center}  
\scalebox{0.75}{
\begin{tikzpicture}[>=Stealth]
% LEFT: X ~ N(0,1)
\begin{scope}[shift={(-4,0)}]
    \node at (2,3) {$X \sim \mathcal{N}(0,1)$};
    
    % Axis
    \draw[->] (-1,0) -- (4,0) node[right] {$x$};
    \draw[->] (0,-0.3) -- (0,3) node[above] {$p_X(x)$};
    
    % Gaussian density (centered at x=1.5, scaled to fit)
    \draw[blue,thick,domain=-0.5:3.5,smooth,samples=100] 
        plot (\x,{2.5*exp(-(\x-1.5)*(\x-1.5)/0.5)});
    \fill[blue!20,opacity=0.6,domain=-0.5:3.5,smooth,samples=100] 
        plot (\x,{2.5*exp(-(\x-1.5)*(\x-1.5)/0.5)}) -- (3.5,0) -- (-0.5,0) -- cycle;
    
    % Highlighted region (one standard deviation around mean)
    \fill[blue!50,opacity=0.8,domain=0.5:2.5,smooth,samples=100] 
        plot (\x,{2.5*exp(-(\x-1.5)*(\x-1.5)/0.5)}) -- (2.5,0) -- (0.5,0) -- cycle;
    
    % Labels
    % \node[below] at (1.5,0) {$0$};
    \node[below] at (0.5,0) {\small $-1$};
    \node[below] at (2.5,0) {\small $1$};
    \node[left] at (0,2.5) {\small $0.4$};
   
    % Probability in middle
    \node at (1.5,1.2) {$P_X(g^{-1}(C)) \approx 0.68$};
    
    % Probability annotation
    \draw[<->,thick] (0.5,-0.6) -- (2.5,-0.6);
    \node[below] at (1.5,-0.6) {\small $\sigma = 1$};
    \node[above] at (1.5,-0.6) {\small $g^{-1}(C) = [-1, 1]$};
\end{scope}

% Arrow with transformation
\node at (1.5,-0.8) {\color{carnelian}$P_X(g^{-1}(C)) = P_Y(C) \approx 0.68$};
\draw[->,very thick] (-0,1.8) -- (2.5,1.8) node[midway,above] {$g(x) = 2x+3$};
\draw[<-,thick] (-0,0.8) -- (2.5,0.8) node[midway,above] {preimage};

% RIGHT: Y ~ N(3,4)
\begin{scope}[shift={(0.5,0)}]
    \node at (6,3) {$Y \sim \mathcal{N}(3,4)$};
    
    % Axis
    \draw[->] (2,0) -- (10,0) node[right] {$y$};
    \draw[->] (3,-0.3) -- (3,3) node[above] {$p_Y(y)$};
    
    % Gaussian density (centered at y=6, which is g(0)=3, variance 4)
    \draw[red,thick,domain=2.5:9.5,smooth,samples=100] 
        plot (\x,{1.25*exp(-(\x-6)*(\x-6)/2)});
    \fill[red!20,opacity=0.6,domain=2.5:9.5,smooth,samples=100] 
        plot (\x,{1.25*exp(-(\x-6)*(\x-6)/2)}) -- (9.5,0) -- (2.5,0) -- cycle;
    
    % Highlighted region (one standard deviation: sigma=2)
    \fill[red!50,opacity=0.8,domain=4:8,smooth,samples=100] 
        plot (\x,{1.25*exp(-(\x-6)*(\x-6)/2)}) -- (8,0) -- (4,0) -- cycle;
    
    % Labels
    % \node[below] at (6,0) {$3$};
    \node[below] at (4,0) {\small $1$};
    \node[below] at (8,0) {\small $5$};
    \node[left] at (3,1.25) {\small $0.2$};
      
    % Probability in middle
    \node at (6,0.6) {$P_Y(C) \approx 0.68$};
    
    % Probability annotation
    \draw[<->,thick] (4,-0.6) -- (8,-0.6);
    \node[below] at (6,-0.6) {\small $\sigma = 2$};
    \node[above] at (6,-0.6) {\small $C = [1, 5]$};
\end{scope}
\end{tikzpicture}
}
\end{center}

\vskip 0.5em
\structure{Key insight:}
\begin{itemize}
\item $g$ stretches space: standard deviation doubles ($1 \to 2$)
\item same probability ($\approx 68\%$) distributed over larger space
\item peak density halves: $\max p_Y \approx 0.2 = \frac{1}{2} \cdot 0.4$
\end{itemize}

\alert{Result: $Y \sim \mathcal{N}(3, 4)$ - mean shifts to 3, variance scales to $2^2 = 4$}

\end{frame}

\begin{frame}{Example: Gaussian to Chi-square distribution}

\structure{Setup:} $X \sim \mathcal{N}(0, 1)$, transformation $g(x) = x^2$, find distribution of $Y = g(X)$

\vskip 0.5em
\begin{center}  
\scalebox{0.75}{
\begin{tikzpicture}[>=Stealth]
% LEFT: X ~ N(0,1)
\begin{scope}[shift={(-4.5,0)}]
    \node at (1.5,2.5) {$X \sim \mathcal{N}(0,1)$};
    
    % Axis
    \draw[->] (-3.5,0) -- (3.5,0) node[right] {$x$};
    \draw[->] (0,-0.3) -- (0,3) node[above] {$p_X(x)$};
    
    % Gaussian density (centered at 0)
    \draw[blue,thick,domain=-3:3,smooth,samples=100] 
        plot (\x,{2.5*exp(-\x*\x/2)});
    \fill[blue!20,opacity=0.6,domain=-3:3,smooth,samples=100] 
        plot (\x,{2.5*exp(-\x*\x/2)}) -- (3,0) -- (-3,0) -- cycle;
    
    % Highlighted regions that map to [0,1]
    \fill[blue!50,opacity=0.8,domain=-1:0,smooth,samples=50] 
        plot (\x,{2.5*exp(-\x*\x/2)}) -- (0,0) -- (-1,0) -- cycle;
    \fill[blue!50,opacity=0.8,domain=0:1,smooth,samples=50] 
        plot (\x,{2.5*exp(-\x*\x/2)}) -- (1,0) -- (0,0) -- cycle;
    
    % Probability in middle
    \node at (1,1.2) {$P_X(g^{-1}(C)) \approx 0.68$};

    % Labels
    \node[below] at (0,0) {$0$};
    \node[below] at (-1,0) {\small $-1$};
    \node[below] at (1,0) {\small $1$};
    \node[left] at (0,2.5) {\small $0.4$};
   
    % Annotation
    \draw[<->,thick] (-1,-0.6) -- (1,-0.6);
    \node[below] at (0,-0.6) {\small $g^{-1}(C) = [-1,1]$};
\end{scope}

% Arrow with transformation
% \node at (0,-0.5) {\color{carnelian}$g(x) = x^2$};
% \node at (0,-1) {\color{carnelian}(non-invertible!)};
\node at (0,-0.8) {\color{carnelian}$P_X(g^{-1}(C)) = P_Y(C) \approx 0.68$};
\draw[->,very thick] (-1,1.8) -- (1.5,1.8) node[midway,above] {$g(x) = x^2$};
\draw[<-,thick] (-1,0.8) -- (1.5,0.8) node[midway,above] {preimage};

% RIGHT: Y ~ Chi-square(1)
\begin{scope}[shift={(2,0)}]
    \node at (3,2.5) {$Y \sim \chi^2_1$};
    
    % Axis
    \draw[->] (-0.5,0) -- (6.5,0) node[right] {$y$};
    \draw[->] (0,-0.3) -- (0,3) node[above] {$p_Y(y)$};
    
    % Chi-square density with 1 d.f.: (1/sqrt(2*pi*y)) * exp(-y/2)
    \draw[red,thick,domain=0.1:6,smooth,samples=100] 
        plot (\x,{1.5/sqrt(\x)*exp(-\x/2)});
    \fill[red!20,opacity=0.6,domain=0.1:6,smooth,samples=100] 
        plot (\x,{1.5/sqrt(\x)*exp(-\x/2)}) -- (6,0) -- (0.1,0) -- cycle;
    
    % Highlighted region [0,1]
    \fill[red!50,opacity=0.8,domain=0.1:1,smooth,samples=50] 
        plot (\x,{1.5/sqrt(\x)*exp(-\x/2)}) -- (1,0) -- (0.1,0) -- cycle;
    
    % Probability in middle
    \node at (1,1.2) {$P_Y(C) \approx 0.68$};

    % Labels
    \node[below] at (0,0) {$0$};
    \node[below] at (1,0) {\small $1$};
    \node[below] at (3,0) {\small $3$};
      
    % Annotation
    \draw[<->,thick] (0.1,-0.6) -- (1,-0.6);
    \node[below] at (0.55,-0.6) {\small $C = [0,1]$};
\end{scope}
\end{tikzpicture}
}
\end{center}

\vskip 0.5em
\structure{Key observations:}
\begin{itemize}
\item non-invertible: both $x$ and $-x$ map to $x^2$ (two preimages!)
\item symmetric regions $[-1,0]$ and $[0,1]$ both map to $[0,1]$
\item density piles up near zero: $p_Y(y) \to \infty$ as $y \to 0^+$
\end{itemize}

\alert{Non-affine transformation changes distribution family: Gaussian $\to$ Chi-square}

\end{frame}

\note[enumerate]
{
\item This example shows a fundamentally different transformation: non-linear and non-invertible
\item For $g(x) = x^2$: each positive $y$ has two preimages $\pm\sqrt{y}$
\item Chi-square with 1 d.f. is the distribution of the square of a standard normal
\item Density near zero is high because small intervals near 0 in the Gaussian map to very small intervals in $[0,\infty)$
\item The change of variables formula still works, but we need to account for both preimages
\item This will be important when we derive the formula in Section 5
\item Shows that push-forward can change distribution families dramatically
}