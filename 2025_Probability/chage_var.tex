\section{Change of variables at density level}
\begin{frame}{From push-forward to change of variables}

\structure{What we saw:} uniform distribution + affine transformation
\begin{itemize}
\item $X \sim \text{Uniform}[0,1]$, $g(x) = 2x + 3$, $Y = g(X)$
\item stretching by factor 2 $\Rightarrow$ density halves
\item easy to compute: $p_Y = \frac{1}{2}$
\end{itemize}

\vskip 1em
\structure{General question:}\\
Given arbitrary distribution $p_X$ and transformation $g$, how do we compute $p_Y$?

\vskip 1em
\structure{Challenge:}
\begin{itemize}
\item not just uniform distributions
\item not just affine transformations
\item need general formula relating $p_Y$ to $p_X$ and $g$
\end{itemize}

\vskip 0.5em
\alert{Goal: derive the change of variables formula with Jacobian determinant}

\end{frame}

\note[enumerate]
{
\item The uniform example was special - constant density, linear transformation
\item In ML: we use complex distributions (Gaussian, data distributions) and complex transformations (neural networks)
\item Need to understand how densities transform in general
\item This is the change of variables formula - fundamental for normalizing flows, diffusion models, etc.
}

\begin{frame}{Step 1: From push-forward to CDF}

\structure{Recall:} push-forward at measure level
\[
P_Y(C) = P_X(g^{-1}(C))
\]

\vskip 0.5em
\structure{Choose special set:} $C = (-\infty, y]$, then $P_Y((-\infty, y]) = F_Y(y)$ \alert{- CDF!}

\vskip 1em
\structure{What is $g^{-1}((-\infty, y])$?}
\begin{itemize}
\item If $g$ \alert{increasing}: $g^{-1}((-\infty, y]) = (-\infty, g^{-1}(y)]$
  \[
  \alert{\Rightarrow F_Y(y) = F_X(g^{-1}(y))}
  \]
\item If $g$ \alert{decreasing}: $g^{-1}((-\infty, y]) = [g^{-1}(y), \infty)$
  \[
  \alert{\Rightarrow F_Y(y) = 1 - F_X(g^{-1}(y))}
  \]
\end{itemize}

\end{frame}

\note[enumerate]
{
\item Key step: specialize push-forward to the set $(-\infty, y]$ which gives CDF
\item Increasing function: preimage preserves order, so $g^{-1}((-\infty, y]) = (-\infty, g^{-1}(y)]$
\item Decreasing function: preimage reverses order, so $g^{-1}((-\infty, y]) = [g^{-1}(y), \infty)$
\item This gives us exact formulas relating CDFs
\item Next: differentiate to get density formula
}

\begin{frame}{Step 2: Differentiate to get density}

\vskip 0.5em
\structure{Case 1: $g$ increasing}
\[
p_Y(y) = \frac{dF_Y}{dy}(y) = \frac{d}{dy} F_X(g^{-1}(y)) = p_X(g^{-1}(y)) \cdot \frac{dg^{-1}}{dy}(y)
\]
Note: $\frac{dg^{-1}}{dy} > 0$ for increasing $g$

\vskip 1em
\structure{Case 2: $g$ decreasing}
\[
p_Y(y) = \frac{dF_Y}{dy}(y) = \frac{d}{dy}[1 - F_X(g^{-1}(y))] = -p_X(g^{-1}(y)) \cdot \frac{dg^{-1}}{dy}(y)
\]
Note: $\frac{dg^{-1}}{dy} < 0$ for decreasing $g$, so $-\frac{dg^{-1}}{dy} > 0$

\vskip 1em

\[
\alert{\text{Change of varible formula:} \qquad p_Y(y) = p_X(g^{-1}(y)) \left| \frac{dg^{-1}}{dy}(y) \right|}
\]

\end{frame}

\note[enumerate]
{
\item Chain rule for differentiation
\item PDF is derivative of CDF
\item Increasing case: derivative is positive
\item Decreasing case: minus sign from derivative of (1-F), but derivative of $g^{-1}$ is negative, so they cancel to positive
\item Absolute value handles both cases: density must be positive!
\item This explains why we need absolute value in change of variables formula
}

\begin{frame}{Alternative derivation: direct from push-forward}

\structure{Recall:} push-forward with densities (assuming they exist)
\[
P_Y(C) = \int_C p_Y(y) \, dy = \int_{g^{-1}(C)} p_X(x) \, dx = P_X(g^{-1}(C))
\]

\vskip 0.5em
\structure{Change integration variable:} substitute $x = g^{-1}(y)$, then $dx = \frac{dg^{-1}}{dy}(y) \, dy$
\[
\int_C p_Y(y) \, dy = \int_{g^{-1}(C)} p_X(x) \, dx = \int_C p_X(g^{-1}(y)) \left| \frac{dg^{-1}}{dy}(y) \right| \, dy
\]

\vskip 0.5em
Since this holds for all $C$, integrands must be equal:
\[
\alert{\text{Change of varible formula:} \qquad p_Y(y) = p_X(g^{-1}(y)) \left| \frac{dg^{-1}}{dy}(y) \right|}
\]

\end{frame}

\note[enumerate]
{
\item This derivation uses change of variables formula from calculus directly
\item More direct than the CDF approach, but requires knowing change of variables
\item Absolute value appears because we integrate over sets (not oriented intervals)
\item If integrals are equal for all sets $C$, integrands must be equal
\item Same formula as before - two derivations confirm the result!
}

\begin{frame}{Examples: applying the formula}

\structure{Setup:} transformation $g(x) = 2x + 3$, so $g^{-1}(y) = \frac{y-3}{2}$ and $\frac{dg^{-1}}{dy} = \frac{1}{2}$

\vskip 1em
\structure{Example 1: Uniform}
\[
X \sim \text{Uniform}[0,1]: p_X(x) = 1
\]
\[
p_Y(y) = 1 \cdot \frac{1}{2} = \frac{1}{2} \quad \Rightarrow \quad Y \sim \text{Uniform}[3,5]
\]

\vskip 1em
\structure{Example 2: Gaussian}
\[
X \sim \mathcal{N}(0, 1): p_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}
\]
\[
p_Y(y) = \frac{1}{\sqrt{2\pi}} e^{-(y-3)^2/8} \cdot \frac{1}{2} \quad \Rightarrow \quad Y \sim \mathcal{N}(3, 4)
\]
\end{frame}

\note[enumerate]
{
\item Both examples use same transformation, different distributions
\item Uniform: confirms intuitive result from Section 4
\item Gaussian: mean shifts by 3, variance scales by $2^2 = 4$
\item The derivative $\frac{1}{2}$ accounts for the stretching by factor 2
\item General principle: affine transformation is easy to compute
}

\begin{frame}{Generalization to $\mR^d$}

\structure{In 1D:} derivative $g'(x)$ measures how $g$ stretches/compresses locally

\vskip 1em
\structure{In $\mR^d$:} Jacobian matrix $J_g(x) = \frac{\partial g}{\partial x}(x)$ generalizes the derivative
\begin{itemize}
\item $J_g(x)$ is $d \times d$ matrix of all partial derivatives
\item $\det J_g(x)$ measures local volume scaling factor
\end{itemize}

\vskip 1em
\structure{Change of integration variables in $\mR^d$:}
\[
dx = \left| \det J_{g^{-1}}(y) \right| \, dy
\]

\vskip 1em
\[
\alert{\text{Change of varible formula:} \qquad  p_Y(y) = p_X(g^{-1}(y)) \left| \det J_{g^{-1}}(y) \right| }
\]

\end{frame}

\note[enumerate]
{
\item Jacobian matrix: natural generalization of derivative to multiple dimensions
\item Determinant of Jacobian: measures how volumes scale under transformation
\item Next: geometric interpretation of what the Jacobian determinant means
}

\begin{frame}{Jacobian as linear approximation}

\structure{The Jacobian measures local volume scaling}

\vskip 1em
\structure{Key idea:} Near point $x$, transformation $g$ is approximately linear
\[
g(x + \Delta x) \approx g(x) + J_g(x) \cdot \Delta x
\]
where $J_g(x) = \frac{\partial g}{\partial x}(x)$ is the Jacobian matrix

\vskip 1em
\structure{Volume scaling:}
\begin{itemize}
\item linear map $A$ scales volumes by $|\det A|$
\item $J_g(x)$ is the linear approximation of $g$ at $x$
\item therefore: $g$ scales volumes locally by $|\det J_g(x)|$
\end{itemize}

\vskip 1em
\structure{Consequence:}
\[
\text{volume}(g(B_\epsilon(x))) \approx |\det J_g(x)| \cdot \text{volume}(B_\epsilon(x))
\]
for small ball $B_\epsilon(x)$ around $x$

\end{frame}

\note[enumerate]
{
\item This is the fundamental insight: Jacobian is the best linear approximation
\item In 1D: this is just $g(x + \Delta x) \approx g(x) + g'(x) \Delta x$ (tangent line)
\item In $\mR^d$: Jacobian matrix plays the role of derivative
\item Linear maps scale volumes by their determinant
\item Since $g$ is approximately linear near $x$, it scales volumes by $|\det J_g(x)|$
\item This justifies the change of variables formula
}